# Agentic Certificate Evaluation System

This project implements an intelligent agentic workflow using LangGraph and Google Gemini (Multimodal) to automate the extraction, analysis, and evaluation of university certificates. The system is designed to handle various formats, including PDFs and images, while allowing real-time user intervention and corrections. The project folder also contains two example certificates for testing purposes.

## Project Setup

### 1. Install Requirements
Ensure you have Python installed, then install the necessary dependencies using pip:
```bash
pip install -r requirements.txt
```

### 2. Configure Environment Variables
The system requires a Google API Key to access Gemini models added to the '.env' file included in the project files.
```env
GOOGLE_API_KEY=your_gemini_api_key_here
```

### 3. Execution
To start the interactive agent:
```bash
python main.py
```

---

## Technical Architecture

### 1. Agent State Model
The system architecture is centered around a persistent state managed via a `TypedDict` called `AgentState`. This state acts as the "Single Source of Truth" for the agent during its lifecycle.

*   **messages**: An annotated list of `BaseMessage` objects. It maintains the full chronological history of the interaction, including Human messages, AI reasoning (AIMessage), and Tool outputs.
*   **extracted_data**: A dictionary containing structured data parsed from the certificate. This includes fields like `student_name`, `gpa`, `degree`, and `university`, along with a `corrections_history` to track user-mandated changes.
*   **evaluation_criteria**: A dictionary defining the rules for evaluation, such as `min_gpa` or `required_degree`. This is typically populated based on user instructions.
*   **evaluation_result**: Stores the final outcome of the evaluation, including the PASS/FAIL status and a list of specific reasons or justifications for the decision.
*   **conversation_context**: Tracks metadata such as user intent, scope changes, and internal flags for the interruption logic.

### 2. Step-Selection Logic
The workflow is orchestrated using a LangGraph directed graph, which enables non-linear, state-aware execution.

*   **Agent Node (Reasoning)**: The core logic unit that invokes the LLM. It analyzes the current `AgentState` to determine the next logical step. It uses a system prompt that guides it to prioritize actions: extraction first, then criteria gathering, then evaluation.
*   **Internal LLM Tool Node (Execution) (No External Tools Were Used)**: Handles the execution of tool calls generated by the Agent Node. It performs deterministic operations like updating the state dictionaries or calculating scores.
*   **Conditional Routing**: The `should_continue` function inspects the last message in the state. If the agent has requested tool calls, the flow moves to the Tool Node. If the agent provides a text response, the flow terminates or waits for the next user input.
*   **Looping and Re-evaluation**: The graph structure allows the agent to loop back to previous steps. For example, if a user corrects a GPA value after an evaluation, the agent can transition back to the reasoning node to re-trigger the `calculate_score` tool.

### 3. Context Handling Strategy
The system employs several strategies to manage complex, multimodal context effectively.

*   **Multimodal Integration**: Certificates (PDFs or images) are encoded into base64 and injected into the conversation as vision-capable content blocks. This allows the model to perform direct visual inspection of certificates.
*   **Persistent Short-Term Memory**: By leveraging LangGraph's state management, the agent retains the context of previous tool outputs and user corrections, preventing the loss of information during multi-step tasks.
*   **Real-time Interruption Handling**: The system utilizes a multi-threaded approach for interaction. While the agent node is processing (thinking), a background listener monitors for keyboard input. If the user types:
    *   The current LLM generation is halted.
    *   An auxiliary LLM classifies the interruption as either a "Correction" (modifying the current task) or a "New Instruction" (switching tasks).
    *   The state is updated with a specialized "Interruption Message" that guides the agent on how to pivot its reasoning.
*   **Source Awareness**: When multiple files are provided, the agent explicitly tracks the `source_file` for each data point, ensuring that evaluations remain correctly associated with the relevant document.

### 4. User Intervention Tools
The agent is equipped with specific tools to facilitate human-in-the-loop control:
*   **correct_extracted_data**: Allows the agent (at the user's request) to precisely overwrite extracted fields and log the reason for the change.
*   **override_evaluation_result**: Provides a mechanism for the user to manually set the PASS/FAIL status, bypassing the automated logic while preserving the justification for audit purposes.
